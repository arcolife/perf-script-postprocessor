#!/usr/bin/env python2
# coding: utf-8

# Author: Archit Sharma <archit.py@gmail.com>
# Makes use of data generated by using `perf script`
# ref: http://linux.die.net/man/1/perf-script

import os, sys
import time
import argparse
import pandas as pd
import configparser

pd.options.mode.chained_assignment = None  # default='warn'

class PostProcessor(object):
    '''
    Form a DataFrame from the csv and utilize 
    inhouse functions to calculate delta. '''
    def __init__(self, file_path='', result_path='', order=[], mode=2,):
        self.file_path = file_path
        self.result_path = result_path
        self.mode = mode
        self.pattern = tuple(order)
        self.df_dict = {}

    def load_data(self):
        try:
            self.df = pd.read_csv(self.file_path)
            if self.mode == 3:
                self.df = self.df[self.df.entry.isin(self.pattern)]
                self.df = self.df.reset_index().drop('index', axis=1)

            self.df.convert_objects(convert_numeric=True)
            # self.df['tstamp'] = self.df.apply(lambda row: \
            #     row.tstamp*1000000, axis=1)
        except Exception as E:
            quit(E)
        
    def _process(self, x):
        ''' 
        clean the metric keys to get unique categories.
        Example: kvm_entry/kvm_exit represents kvm as a category
        '''
        return x.replace('_exit_','__').replace('_exit','___')\
                .replace('_entry','___').replace('_enter_','__')
    
    def _process_inverse(self, entry, alternate=False):
        '''
        convert those categories back to metric name as under
        perf script processed data. '''
        if not alternate:
            return entry.replace('___','_exit').replace('___','_entry')\
                        .replace('__','_exit_').replace('__','_enter_')
        else:
            # observe the order of enter/exit is different
            return entry.replace('___','_entry').replace('___','_exit')\
                        .replace('__','_enter_').replace('__','_exit_')    

    def _unique_metrics(self):
        """
        `___` would mean this is meant to be replaced by `_entry`
        and `_exit` later -> special case for kvm_entry/exit
        
        `__` would mean this is meant to be replaced by `_enter_`
        and `_exit_` later -> preserves kvm_entry/exit
        
        `_` would mean no changes -> preserves sched_switch
        """
        self.entries = self.df['entry'].unique().tolist()
        if pd.np.nan in self.entries:
            self.entries.remove(pd.np.nan)
        self.entries = set([self._process(i) for i in self.entries])
        print("*"*22)
        print("Unique metrics found:\n\t%s"%'\n\t'.join(self.entries))

    def prepare_delta(self):
        self.load_data()
        # prepare list of metric categories
        self._unique_metrics()

        try:
            if not os.path.exists(self.result_path):
                os.mkdir(self.result_path)
            # check if pattern actually exists
            assert len(set(self.df['entry'].unique().tolist()) & \
                set(self.pattern)) == len(self.pattern)
        except OSError as E:
            quit(E)
        except AssertionError:
            quit("\nERROR: Pattern supplied doesn't exist in DataFrame")

        data = []

        ## calculate sequential event loops (list of dicts)

        ## ALGO 1
        ## Assumes events are sequential once pattern[-1] is found.
        ## NOTE: df1.set_index('entry')['tstamp'].to_dict() is slower 
        ## than zip()
        indices = self.df[self.df.entry == self.pattern[-1]].index
        pat_len = len(self.pattern)
        for i in indices:
            df1 = self.df.ix[i-(pat_len-1):i]
            data.append(dict(zip(df1.entry, df1.tstamp)))

        ## ALGO 2
        ## Generic algo, gets latest n events in order of pattern
        ## once pattern[-1] is found.. 
        # buf_base = dict.fromkeys(self.pattern[:-1])
        # buf_mirror = buf_base.copy()
        # # calculate sequential event loops (list of dicts)
        # for i in range(len(self.df)):
        #     if self.df.entry[i] == self.pattern[-1]:
        #         buf_base[self.df.entry[i]] = self.df.tstamp[i]
        #         data.append(buf_base.copy())
        #     else:
        #         buf_mirror[self.df.entry[i]] = self.df.tstamp[i]
        #     if not None in buf_mirror.values():
        #         buf_base = buf_mirror.copy()
        #         buf_mirror = dict.fromkeys(self.pattern[:-1])

        # form dataframe from calculated loops data 
        loops = pd.DataFrame(data, columns=self.pattern)

        # import pdb; pdb.set_trace()
        # calculate intra-loop deltas
        for i in range(len(self.pattern)-1):
            current = "delta:%s__%s" % (self.pattern[i+1], 
                self.pattern[i])
            loops.loc[:,current] = loops.loc[:,self.pattern[i+1]] - \
                                     loops.loc[:,self.pattern[i]]
        loops = loops.fillna(0)
        loops.to_csv('%s.csv'%(os.path.join(self.result_path, 'loop_diff')))

        print("*"*22)
        for i in range(len(self.pattern)-1):
            current = "delta:%s__%s" % (self.pattern[i+1], 
                self.pattern[i])
            print("%s stats:" %(current))
            print("\tStandard Dev: %s\n\tMean: %s\n\tMedian: %s" % \
                        (loops[current].std(), 
                         loops[current].mean(), 
                         loops[current].median()))
            print("="*22)

        if self.mode==2:
            for entry in self.entries:
                _tmp = self.df[(self.df['entry'] == \
                                self._process_inverse(entry)) |\
                                    (self.df['entry'] == \
                                    self._process_inverse(entry, alternate=True))]
                _tmp.set_index('entry').diff().to_csv('%s.csv' % \
                    (os.path.join(self.result_path, entry)))

        else:
            if not self.mode==3:
                # if breakup isn't specified, join the dataframes
                # into one single frame and dump that.
                for entry in self.entries:
                    _tmp = self.df[(self.df['entry'] == \
                                    self._process_inverse(entry)) | \
                                       (self.df['entry'] == \
                                        self._process_inverse(entry, alternate=True))]
                    
                    _tmp.loc[:,"diff"] = _tmp.loc[:,"tstamp"].diff()
                    # avoid inplace
                    _tmp = _tmp.drop(_tmp.columns[[0, 1]], axis=1)
                    self.df_dict[entry] = _tmp['diff']

                df1 = pd.DataFrame(self.df_dict)
                df1['entry'] = self.df.entry
                df1['tstamp'] = self.df.tstamp

                # rearrange columns
                cols = df1.columns.tolist()
                cols = cols[-2:] + cols[:-2]
                df1 = df1[cols]

                df1 = df1.fillna(0)
                # dump results
                df1.to_csv('%s.csv'%(os.path.join(self.result_path, 'delta_processed')))

        print("Script was executed with Mode option %d.\nResults have been stored to: %s"\
            %(self.mode, self.result_path))


if __name__=='__main__':
    # Parse configurations
    parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, 
    description="""
    Generate delta of entry/exit points for data from `perf script. 
    This script runs in 3 modes. Those being:

    Mode 0: Produce `delta_processed.csv` with all events together.
    Mode 1: In addition to mode 0, this calculates loop statistics(*)
    Mode 2: breakup result into per-event calculated delta csv files.
    
    *Loop order:
    kvm_exit -> sys_exit_ppoll -> sys_enter_io_submit -> sys_exit_io_submit""")
    # requiredNamed = parser.add_argument_group('required named arguments')
    parser.add_argument('-i', '--input', type=str, 
        default='perf_data.csv',
        help='Absolute Path to input csv file')
    parser.add_argument('-m', '--mode', type=int, 
        default=0,
        help='specify mode as per above documentation')
    parser.add_argument('-o', '--output', type=str, 
        default='/tmp/pp_results',
        help='Absolute Path to output dir')
    parser.add_argument('-c', '--conf', type=str, 
        default='/etc/delta_processor.conf',
        help='Absolute Path to output dir')

    try:
        args = parser.parse_args()

        config = configparser.ConfigParser()
        config.read(args.conf)
        order = config.get('Pattern', 'order').split()

        PP = PostProcessor(
                file_path=args.input, 
                result_path=args.output,
                order=order,
                mode=args.mode)
        a = time.time()
        PP.prepare_delta()
        b = time.time()
        print("Time taken -- prepare_delta() -- %s" % (b-a))
    except Exception as E:
        quit("ERROR: %s\nUnable to execute. Refer to --help. I Quit!"%(E))
