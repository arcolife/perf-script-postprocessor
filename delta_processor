#!/usr/bin/env python2
# coding: utf-8

# Author: Archit Sharma <archit.py@gmail.com>
# Makes use of data generated by using `perf script`
# ref: http://linux.die.net/man/1/perf-script

# Explaining why graphs are not generated for the delta:
# df_dict contains keys as metrics and values and "entry and exit" 
# points for those metrics. even if we create diff'ed version between 
# entry and exit, the no of x-axis points would be be large enough,
# given the length of all kvm entries and size of entry/exit points. 
# Even if this is plotted in nvd3, I don't think one would be able to 
# make out the differences that minute.. 
# Hence we leave it to only producing a delta in a huge csv file.


import os, sys
import argparse
import pandas as pd

pd.options.mode.chained_assignment = None  # default='warn'

class PostProcessor(object):
    '''
    Form a DataFrame from the csv and utilize 
    inhouse functions to calculate delta. '''
    def __init__(self, file_path='', result_path='', mode=2):
        self.file_path = file_path
        self.result_path = result_path
        self.mode = mode
        self.df_dict = {}
        
    def load_data(self):
        try:
            self.df = pd.read_csv(self.file_path)
            self.df.convert_objects(convert_numeric=True)
            self.df['tstamp'] = self.df.apply(lambda row: \
                row.tstamp*1000000, axis=1)
        except Exception as E:
            quit(E)
        
    def _process(self, x):
        ''' 
        clean the metric keys to get unique categories.
        Example: kvm_entry/kvm_exit represents kvm as a category
        '''
        return x.replace('_exit_','__').replace('_exit','___')\
                .replace('_entry','___').replace('_enter_','__')
    
    def _process_inverse(self, entry, alternate=False):
        '''
        convert those categories back to metric name as under
        perf script processed data. '''
        if not alternate:
            return entry.replace('___','_exit').replace('___','_entry')\
                        .replace('__','_exit_').replace('__','_enter_')
        else:
            # observe the order of enter/exit is different
            return entry.replace('___','_entry').replace('___','_exit')\
                        .replace('__','_enter_').replace('__','_exit_')    

    def _unique_metrics(self):
        """
        `___` would mean this is meant to be replaced by `_entry`
        and `_exit` later -> special case for kvm_entry/exit
        
        `__` would mean this is meant to be replaced by `_enter_`
        and `_exit_` later -> preserves kvm_entry/exit
        
        `_` would mean no changes -> preserves sched_switch
        """
        self.entries = self.df['entry'].unique().tolist()
        if pd.np.nan in self.entries:
            self.entries.remove(pd.np.nan)
        self.entries = set([self._process(i) for i in self.entries])
        print("*"*22)
        print("Unique metrics found:\n\t%s"%'\n\t'.join(self.entries))

    def prepare_delta(self):
        # load data
        self.load_data()
        # prepare list of metric categories
        self._unique_metrics()
        # prepare dict of dataframes with keys as category
        # if per-metric csv's are required, generate them!
        if not os.path.exists(self.result_path):
            try:
                os.mkdir(self.result_path)
            except:
                raise

        pattern = ("kvm_exit", "syscallssys_exit_ppoll",\
            "syscallssys_enter_io_submit", "syscallssys_exit_io_submit")

        # To identify loops, I'm filtering last event in given pattern first, 
        # noting down all corresponding indices, then looking for second last 
        # event in the pattern from that dataframe, getting the last element 
        # after filtering. This is apparently taking a lot of time.
        
        # TODO: put a check to see if all pattern entries are 
        # present in the dataframe
        buf_base = dict.fromkeys(pattern[:-1])
        buf_mirror = buf_base.copy()
        data = []                    
        for i in range(len(self.df)):
            if self.df.entry[i] == pattern[-1]:
                buf_base[self.df.entry[i]] = self.df.tstamp[i]
                data.append(buf_base.copy())
            else:
                buf_mirror[self.df.entry[i]] = self.df.tstamp[i]
            if not None in buf_mirror.values():
                buf_base = buf_mirror.copy()
                buf_mirror = dict.fromkeys(pattern[:-1])

        loops = pd.DataFrame(data, columns=pattern)

        # loops.loc[:,"delta__exit_ppoll__kvm_exit"] = loops.loc[:,"kvm_exit"].diff()
        loops.loc[:,"delta__exit_ppoll__kvm_exit"] = \
                                loops.loc[:,"syscallssys_exit_ppoll"] - \
                                 loops.loc[:,"kvm_exit"]
        loops.loc[:,"delta__enter_io_submit__exit_ppoll"] = \
                                loops.loc[:,"syscallssys_enter_io_submit"] - \
                                 loops.loc[:,"syscallssys_exit_ppoll"]
        loops.loc[:,"delta__io_submit"] = loops.loc[:,"syscallssys_exit_io_submit"] - \
                                             loops.loc[:,"syscallssys_enter_io_submit"]
                        
        loops = loops.fillna(0)

        print("*"*22)
        print("delta__exit_ppoll__kvm_exit stats:")
        print("\tStandard Dev: %s\n\tMean: %s\n\tMedian: %s" % \
                    (loops.delta__exit_ppoll__kvm_exit.std(), 
                     loops.delta__exit_ppoll__kvm_exit.mean(), 
                     loops.delta__exit_ppoll__kvm_exit.median()))

        print("="*22)
        print("delta__enter_io_submit__exit_ppoll stats:")
        print("\tStandard Dev: %s\n\tMean: %s\n\tMedian: %s" % \
                    (loops.delta__enter_io_submit__exit_ppoll.std(), 
                     loops.delta__enter_io_submit__exit_ppoll.mean(), 
                     loops.delta__enter_io_submit__exit_ppoll.median()))

        print("="*22)
        print("delta__io_submit stats:")
        print("\tStandard Dev: %s\n\tMean: %s\n\tMedian: %s" % \
                    (loops.delta__io_submit.std(), 
                     loops.delta__io_submit.mean(), 
                     loops.delta__io_submit.median()))

        print("*"*22)
        loops.to_csv('%s.csv'%(os.path.join(self.result_path, 'loop_diff')))

        if self.mode==2:
            for entry in self.entries:
                _tmp = self.df[(self.df['entry'] == \
                                self._process_inverse(entry)) |\
                                    (self.df['entry'] == \
                                    self._process_inverse(entry, alternate=True))]
                
                # dump results
                _tmp.set_index('entry').diff().to_csv('%s.csv' % \
                    (os.path.join(self.result_path, entry)))

        else:
            if not self.mode==3:
                # if breakup isn't specified, join the dataframes
                # into one single frame and dump that.
                for entry in self.entries:
                    _tmp = self.df[(self.df['entry'] == \
                                    self._process_inverse(entry)) | \
                                       (self.df['entry'] == \
                                        self._process_inverse(entry, alternate=True))]
                    
                    _tmp.loc[:,"diff"] = _tmp.loc[:,"tstamp"].diff()
                    # avoid inplace
                    _tmp = _tmp.drop(_tmp.columns[[0, 1]], axis=1)
                    self.df_dict[entry] = _tmp['diff']

                df1 = pd.DataFrame(self.df_dict)
                
                # self.df = self.df.drop(self.df.columns, axis=1)
                # self.df = self.df.drop(self.df.index, axis=0)

                # del _tmp
                # del self.df_dict

                df1['entry'] = self.df.entry
                df1['tstamp'] = self.df.tstamp

                # del self.df

                # rearrange columns
                cols = df1.columns.tolist()
                cols = cols[-2:] + cols[:-2]
                df1 = df1[cols]

                df1 = df1.fillna(0)
                # dump results
                df1.to_csv('%s.csv'%(os.path.join(self.result_path, 'delta_processed')))

        print("Script was executed with Mode option %d.\nResults have been stored to: %s"\
            %(self.mode, self.result_path))


if __name__=='__main__':
    # Parse configurations
    parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, 
    description="""
    Generate delta of entry/exit points for data from `perf script. 
    This script runs in 3 modes. Those being:

    Mode 0: Produce `delta_processed.csv` with all events together.
    Mode 1: In addition to mode 0, this calculates loop statistics(*)
    Mode 2: breakup result into per-event calculated delta csv files.
    
    *Loop order:
    kvm_exit -> sys_exit_ppoll -> sys_enter_io_submit -> sys_exit_io_submit""")
    # requiredNamed = parser.add_argument_group('required named arguments')
    parser.add_argument('-i', '--input', type=str, 
        default='perf_data.csv', 
        help='Absolute Path to input csv file')
    parser.add_argument('-m', '--mode', type=int, 
        default=0,  
        help='specify mode as per above documentation')
    parser.add_argument('-o', '--output', type=str, 
        default='/tmp/pp_results',
        help='Absolute Path to output dir')

    args = parser.parse_args()
    try:
        PP = PostProcessor(
                file_path=args.input, 
                result_path=args.output,
                mode=args.mode)
        PP.prepare_delta()
    except Exception as E:
        quit("ERROR: %s\nUnable to execute. Refer to --help. I Quit!"%(E))
