#!/usr/bin/env python2
# coding: utf-8

# Author: Archit Sharma <archit.py@gmail.com>
# Makes use of data generated by using `perf script`
# ref: http://linux.die.net/man/1/perf-script

# Explaining why graphs are not generated for the delta:
# df_dict contains keys as metrics and values and "entry and exit" 
# points for those metrics. even if we create diff'ed version between 
# entry and exit, the no of x-axis points would be be large enough,
# given the length of all kvm entries and size of entry/exit points. 
# Even if this is plotted in nvd3, I don't think one would be able to 
# make out the differences that minute.. Hence we leave it to only producing
# a delta in a huge csv file.


import os, sys
import argparse
import pandas as pd

pd.options.mode.chained_assignment = None  # default='warn'

class PostProcessor(object):
    '''
    Form a DataFrame from the csv and utilize 
    inhouse functions to calculate delta. '''
    def __init__(self, file_path='', result_path='', mode=2):
        self.file_path = file_path
        self.result_path = result_path
        self.mode = mode
        self.df_dict = {}
        
    def load_data(self):
        try:
            self.df = pd.read_csv(self.file_path)
            self.df.convert_objects(convert_numeric=True)
            self.df['tstamp'] = self.df.apply(lambda row: row.tstamp*1000000, axis=1)
        except Exception as E:
            quit(E)
        
    def _process(self, x):
        ''' 
        clean the metric keys to get unique categories.
        Example: kvm_entry/kvm_exit represents kvm as a category
        '''
        return x.replace('_exit_','__').replace('_exit','___')\
                .replace('_entry','___').replace('_enter_','__')
    
    def _process_inverse(self, entry, alternate=False):
        '''
        convert those categories back to metric name as under
        perf script processed data. '''
        if not alternate:
            return entry.replace('___','_exit').replace('___','_entry')\
                        .replace('__','_exit_').replace('__','_enter_')
        else:
            # observe the order of enter/exit is different
            return entry.replace('___','_entry').replace('___','_exit')\
                        .replace('__','_enter_').replace('__','_exit_')    

    def _unique_metrics(self):
        """
        `___` would mean this is meant to be replaced by `_entry`
        and `_exit` later -> special case for kvm_entry/exit
        
        `__` would mean this is meant to be replaced by `_enter_`
        and `_exit_` later -> preserves kvm_entry/exit
        
        `_` would mean no changes -> preserves sched_switch
        """
        self.entries = self.df['entry'].unique().tolist()
        if pd.np.nan in self.entries:
            self.entries.remove(pd.np.nan)
        self.entries = set([self._process(i) for i in self.entries])
        print("Unique metrics found:\n\t%s"%'\n\t'.join(self.entries))

    def prepare_delta(self):
        # load data
        self.load_data()
        # prepare list of metric categories
        self._unique_metrics()
        # prepare dict of dataframes with keys as category
        # if per-metric csv's are required, generate them!
        if not os.path.exists(self.result_path):
            try:
                os.mkdir(self.result_path)
            except:
                raise

        if self.mode==2:
            for entry in self.entries:
                _tmp = self.df[(self.df['entry'] == self._process_inverse(entry)) |\
                                    (self.df['entry'] == self._process_inverse(entry, alternate=True))]
                
                # dump results
                _tmp.set_index('entry').diff().to_csv('%s.csv'%(os.path.join(self.result_path, entry)))

        else:
            # if breakup isn't specified, join the dataframes
            # into one single frame and dump that.
            for entry in self.entries:
                _tmp = self.df[(self.df['entry'] == self._process_inverse(entry)) | \
                                   (self.df['entry'] == self._process_inverse(entry, alternate=True))]
                
                _tmp.loc[:,"diff"] = _tmp.loc[:,"tstamp"].diff()
                # avoid inplace
                _tmp = _tmp.drop(_tmp.columns[[0, 1]], axis=1)
                self.df_dict[entry] = _tmp['diff']

            del _tmp
            del df
            
            df1 = pd.DataFrame(self.df_dict)
            df1['entry'] = self.df.entry
            df1['tstamp'] = self.df.tstamp
            # rearrange columns
            cols = df1.columns.tolist()
            cols = cols[-2:] + cols[:-2]
            df1 = df1[cols]
            # dump results
            df1.to_csv('%s.csv'%(os.path.join(self.result_path, 'delta_processed')))
            
            if self.mode==1:
                # TODO: optimize this
                pattern = ("kvm_exit","syscallssys_exit_ppoll","syscallssys_enter_io_submit","syscallssys_exit_io_submit")

                _tmp = df1.loc[df1['entry'].isin(pattern)]
                # avoid inplace
                _tmp = _tmp.drop(_tmp.columns[2:].tolist(), axis=1)

                checklist_1 = _tmp.loc[_tmp['entry'] == pattern[-1]]
                indices_1 = checklist.index.tolist()
                data = []

                for pat_3_loc in indices_1:
                    x = _tmp.ix[:pat_3_loc]
                    pat_2_loc = x[x.entry == pattern[-2]].iloc[-1].name
                    pat_1_loc = x[x.entry == pattern[1]].iloc[-1].name
                    pat_0_loc = x[x.entry == pattern[0]].iloc[-1].name
                    data.append([_tmp.ix[pat_0_loc].tstamp,
                                _tmp.ix[pat_1_loc].tstamp,
                                _tmp.ix[pat_2_loc].tstamp,
                                _tmp.ix[pat_3_loc].tstamp])
                    _tmp = _tmp.ix[pat_3_loc:]
                    
                loops = pd.DataFrame(data, columns=pattern)
                loops.loc[:,"kvm_exit_diffs"] = loops.loc[:,"kvm_exit"].diff()
                loops.loc[:,"io_submit_delta"] = loops.loc[:,"syscallssys_exit_io_submit"] - loops.loc[:,"syscallssys_enter_io_submit"]
                loops.to_csv('%s.csv'%(os.path.join(self.result_path, 'loop_diff')))

        del df_dict
        print("Script was executed with Mode option %d.\nResults have been stored to: %s"\
            %(self.mode, self.result_path))


if __name__=='__main__':
    # Parse configurations
    parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, 
    description="""
    Generate delta of entry/exit points for data from `perf script. 
    This script runs in 3 modes. Those being:

    Mode 0: Produce `delta_processed.csv` with all events together.
    Mode 1: In addition to mode 0, this calculates loop statistics(*)
    Mode 2: breakup result into per-event calculated delta csv files.
    
    *Loop order:
    kvm_exit -> sys_exit_ppoll -> sys_enter_io_submit -> sys_exit_io_submit""")
    # requiredNamed = parser.add_argument_group('required named arguments')
    parser.add_argument('-i', '--input', type=str, 
        default='perf_data.csv', 
        help='Absolute Path to input csv file')
    parser.add_argument('-m', '--mode', type=int, 
        default=0,  
        help='specify mode as per above documentation')
    parser.add_argument('-o', '--output', type=str, 
        default='/tmp/pp_results',
        help='Absolute Path to output dir')

    args = parser.parse_args()
    try:
        PP = PostProcessor(
                file_path=args.input, 
                result_path=args.output,
                mode=args.mode)
        Delta = PP.prepare_delta()
    except Exception as E:
        quit("%s\nUnable to execute. Refer to --help. I Quit!"%(E))
